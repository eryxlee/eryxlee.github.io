<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>AGI Explained</title><meta name="author" content="Eryx Lee"><meta name="copyright" content="Eryx Lee"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="AGI Explained">
<meta property="og:url" content="https://blog.agiexplained.com/page/6/index.html">
<meta property="og:site_name" content="AGI Explained">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pics.agiexplained.com/i/2024/03/05/171847_2.png">
<meta property="article:author" content="Eryx Lee">
<meta property="article:tag" content="AI,AGI,AIGC,OpenAI,ChatGPT,GPT,Multimodal,LLM,NLP,Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pics.agiexplained.com/i/2024/03/05/171847_2.png"><link rel="shortcut icon" href="https://pics.agiexplained.com/i/2024/03/05/171847.ico"><link rel="canonical" href="https://blog.agiexplained.com/page/6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?8823ed47591706858ef7d0072102a1be";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'AGI Explained',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-04-02 16:58:28'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://pics.agiexplained.com/i/2024/03/05/171847_2.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">62</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://kb.agiexplained.com"><i class="fa-fw fas fa-book"></i><span> 知识库</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://kb.agiexplained.com/#/ai/aiindex"><i class="fa-fw fas fa-book"></i><span> AI资源清单</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="AGI Explained"><span class="site-name">AGI Explained</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="https://kb.agiexplained.com"><i class="fa-fw fas fa-book"></i><span> 知识库</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://kb.agiexplained.com/#/ai/aiindex"><i class="fa-fw fas fa-book"></i><span> AI资源清单</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/17/LangChain-LCEL-quickstart/" title="LangChain LCEL 起步（一）">LangChain LCEL 起步（一）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-17T13:36:54.000Z" title="发表于 2024-03-17 21:36:54">2024-03-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LCEL简化了从基础组件构建复杂链的过程，并支持像流处理、并行处理和日志记录等开箱即用的功能。
最简案例: prompt + model + output parser最基本也是最常见的 LCEL 案例就是将一个 Prompt 模版跟一个模型串联起来。下面，我们将创建一条链，它接收一个主题并由此生成一个笑话。
12345678910111213141516from langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_openai import ChatOpenAI# Prompt模版prompt = ChatPromptTemplate.from_template(&quot;tell me a short joke about &#123;topic&#125;&quot;)# 模型model = ChatOpenAI(model=&quot;gpt-4&quot;)# 输出解析器output_pa ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/17/LangChain-LCEL-intro/" title="LangChain LCEL 简介">LangChain LCEL 简介</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-17T13:36:21.000Z" title="发表于 2024-03-17 21:36:21">2024-03-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LangChain表达式语言（ LCEL），是一种声明式的语言，通过它可以轻松地将链组合在一起。 LCEL 从设计的第一天开始就是为了支持 原型即产品，代码无变更 理念的。从最简单的 “Prompt + LLM” 链到最复杂的链（曾有过成功在生产中运行具有数百个步骤的 LCEL 链的案例）。
以下是几个使用 LCEL 的好处：
支持流式传输 当使用 LCEL 构建链时，用户将获得最佳的首次令牌时间（从开始到第一个输出块出现所消耗的时间）。对于某些链来说，这意味着令牌直接从一个 LLM 流式传输到一个支持流式的输出解析器，用户将以与 LLM 输入方输入原始token的相同速率获得解析后的增量输出块。
支持异步 使用 LCEL 构建的任何链都可以使用同步 API（例如在 Jupyter notebook 中进行的原型开发）以及异步 API（例如在 LangServe 服务器中运行）进行调用。这使得原型开发和生产环境中可以使用相同的代码，它们在生产环境将可以获得出色的性能，以及在同一个服务器上处理许多并发请求。
优化的并行执行 每当 LCEL 链具有可以并行执行的步骤（例如，从多个检索器中获 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/15/LangChain-langserve/" title="LangChain LangServe入门">LangChain LangServe入门</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-15T00:27:42.000Z" title="发表于 2024-03-15 08:27:42">2024-03-15</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">现在我们已经建立了一个应用程序，但如果需要让它对外提供服务，就需要引入 LangServe 。LangServe 帮助开发人员将 LangChain 链部署为 REST API。使用 LangChain 并不一定需要使用 LangServe，但在本指南中，我们将展示如何使用 LangServe 部署您的应用程序。虽然之前大部分程序&#x2F;示例都是在 Jupyter Notebook 中运行的，现在我们离开那个环境。我们将创建一个 Python 文件，然后从命令行与之交互。
在开始之前，先安装LangServe
1pip install &quot;langserve[all]&quot;

Server端要创建一个LangChain应用服务器，我们首先需要编写一个serve.py文件。该文件包含LangChain应用的服务逻辑，包括：

刚刚构建的链定义
一个 FastAPI 应用（这里使用FastAPI框架）
通过 langserve.add_routes 定义一个链服务提供的路由

123456789101112131415161718192021222324252627282 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/13/LangChain-quickstart-4/" title="快速构建 LangChain 应用（四）">快速构建 LangChain 应用（四）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-13T01:23:02.000Z" title="发表于 2024-03-13 09:23:02">2024-03-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">四、Agent入门到目前为止，我们创建的所有示例链的每一步都是在事先知道的情况下进行的。最后，我们将学习怎么使用LangChain的agent，在这个例子中，LLM将决定下一步采取哪些步骤。

注意：本文中我们仅展示OpenAI模型来创建的agent，迄今为止，本地化模型在这方面尚不成熟。

在构建Agent时，首先要决定它应该能够访问哪些工具。在这个例子中，我们将给代理提供两个工具：

我们刚刚创建的检索器。这将使它能够轻松回答有关 LangSmith 的问题。 
一个搜索工具。这将使它能够轻松回答需要最新信息的问题。

首先，让我们将刚刚创建的检索器设置成一个工具：
1234567from langchain.tools.retriever import create_retriever_toolretriever_tool = create_retriever_tool(    retriever,    &quot;langsmith_search&quot;,    &quot;Search for information about LangSmith. For any q ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/12/LangChain-quickstart-3/" title="快速构建 LangChain 应用（三）">快速构建 LangChain 应用（三）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-11T22:02:11.000Z" title="发表于 2024-03-12 06:02:11">2024-03-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">三、会话式检索链到目前为止我们创建的链还只能回答单个问题。我们正在构建的最主要的 LLM 应用程序类型之一是聊天机器人。那么，我们如何将这个链转换成一个能够回答后续问题的链呢？
在这里，我们仍然可以使用 create_retrieval_chain 函数，但是我们需要改变两件事：

检索方法现在不仅应考虑最近的输入，还应考虑整个历史记录。

最终的 LLM 链也应考虑整个历史记录。


更新检索为了更新检索，我们将创建一个新的链。这个链将输入（input）和对话历史记录（chat_history）作为输入，并使用一个 LLM 生成一个搜索查询。
1234567891011from langchain.chains import create_history_aware_retrieverfrom langchain_core.prompts import MessagesPlaceholder# 首先我们需要创建一个提示词，可以将其传递给 一个LLM 来生成这个搜索查询prompt = ChatPromptTemplate.from_messages([    MessagesPlac ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/11/LangChain-quickstart-2/" title="快速构建 LangChain 应用（二）">快速构建 LangChain 应用（二）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-10T16:32:13.000Z" title="发表于 2024-03-11 00:32:13">2024-03-11</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">二、检索链为了能够正确回答原始问题 (“how can langsmith help with testing？”), 我们需要向 LLM 提供额外的上下文信息。这里，我们可以通过检索来实现这一点。当有太多数据无法直接传递给 LLM 时，检索就非常有用了。您可以使用检索器来获取最相关的内容并将其传递进去。
在这个过程中，我们将从检索器中查找相关的文档，然后将其传递到提示词Prompt中。检索器的背后可以是任何东西 -  SQL数据表、互联网等端。下面，我们将使用一个向量存储组件并将其用作检索器。
首先，我们需要加载想要索引的数据。为了实现这一点，我们将使用 WebBaseLoader。在使用它之前，先要安装 BeautifulSoup：
1pip install beautifulsoup4

然后，我们可以引入WebBaseLoader、实例化并加载文档。
1234from langchain_community.document_loaders import WebBaseLoaderloader = WebBaseLoader(&quot;https://docs.smith.l ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/10/LangChain-quickstart/" title="快速构建 LangChain 应用（一）">快速构建 LangChain 应用（一）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-10T03:49:05.000Z" title="发表于 2024-03-10 11:49:05">2024-03-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LangChain 使您能够构建连接外部数据和计算资源到大型语言模型（LLM）的应用程序。下面我们将一步步来演示这个构建过程。
首先，我们将从简单的 LLM 链开始，它仅依赖于提示模板中的信息来响应。
接下来，我们将构建一个检索链，该链从单独的数据库中获取数据，并将这些数据传递给提示模板。
然后，我们将加入聊天历史记录，以创建一个会话检索链。这使您能够以聊天的方式与这个 LLM 互动，让它记住之前的问题。
最后，我们将构建一个代理人，该代理人利用 LLM 来判断是否需要检索数据来回答问题。
一、LLM 链1.1、基于OpenAI的实现我们可以通过API来访问LLM，比如OpenAI。在开始之前，需要先安装LangChain x OpenAI 集成包pip install langchain-openai。其次设置环境变量OPENAI_API_KEYexport OPENAI_API_KEY=&quot;...&quot;。然后开始初始化。
123from langchain_openai import ChatOpenAIllm = ChatOpenAI()  # 也可以通过参数传递o ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/09/LangChain-libraries/" title="LangChain 库构成">LangChain 库构成</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-09T05:52:29.000Z" title="发表于 2024-03-09 13:52:29">2024-03-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LangChain库提供了一系列组件和集成工具，使得开发者能够更方便地与语言模型进行交互。这些组件是模块化的，易于使用，无论是否使用LangChain框架的其他部分。
此外，LangChain库还提供了现成的链（off-the-shelf chains），这些链是由多个组件组合而成，用于完成更高级别的任务。现成的链可以帮助开发者快速入门，而组件则使得定制现有链和构建新链变得更加容易。
LangChain库由几个不同的包组成：
1、langchain：包含构成应用程序认知架构的链（Chains）、代理（Agents）和检索策略（Retrieval Strategies）。这些组件是构建智能应用的关键，使得开发者能够创建出具有复杂语言处理能力的应用程序。
这是安装LangChain的最基本要求。LangChain的很多价值在于它与各种模型提供商、数据存储等集成。默认情况下，实现这些功能所需的依赖项并未安装，还需要为特定集成分别安装依赖项。
1pip install langchain



2、langchain-community：提供第三方集成，这意味着开发者可以方便地集成和使用来自社 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/07/langchain-application-develop-workflow/" title="LangChain 应用基本开发流程">LangChain 应用基本开发流程</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-07T11:38:17.000Z" title="发表于 2024-03-07 19:38:17">2024-03-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LangChain框架的使用涉及多个步骤，这些步骤通常包括设置环境、定义任务和链、配置组件，以及最终运行和评估你的应用程序。下面是一个大致的指南，帮助你了解如何使用LangChain框架：

安装和设置环境：

首先，确保你的开发环境中安装了Python（或JavaScript，取决于你选择的库）。
然后，使用pip（或npm）安装LangChain库。


理解任务和需求：

在开始使用LangChain之前，明确你的应用程序需要完成的任务和目标。
思考哪些语言模型、检索器、生成器等组件最适合你的任务。


定义链和组件：

在LangChain中，链是由一系列组件构成的，这些组件共同完成了特定的任务。
你需要根据你的任务定义链的结构，并配置每个组件的参数。


加载和集成模型：

根据你的需求，加载适当的语言模型（如GPT、BERT等）。
配置模型的输入和输出格式，确保它们与你的链的其他部分兼容。


实现数据处理和特征工程：

如果需要，实现数据预处理步骤，如分词、清洗、编码等。
设计特征提取方法，以便为模型提供有用的上下文信息。


编写和配置链：

使用LangChain的A ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/07/langchain-introduction/" title="LangChain 简介">LangChain 简介</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-07T06:54:40.000Z" title="发表于 2024-03-07 14:54:40">2024-03-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/LangChain/">LangChain</a></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/LangChain/">LangChain</a></span></div><div class="content">LangChain是一个基于语言模型的应用程序开发框架。它使应用程序能够：

上下文感知能力：将语言模型与上下文来源（如提示指令、少量示例、用于支撑响应的内容等）相连接；

推理能力：依赖于语言模型进行推理（如基于提供的上下文回答问题、以及需要采取什么行动等）。


通过使用LangChain，开发人员能够创建出能够理解用户意图、利用上下文信息、并进行智能推理的应用程序，从而提供更自然、更准确的用户体验。无论是构建聊天机器人、智能助手，还是其他复杂的自然语言处理应用，LangChain都提供了一个强大而灵活的工具集，帮助开发人员快速实现他们的创意和目标。
LangChain主要由以下几个部分组成：

LangChain库提供了一套强大的工具和组件，支持开发者通过Python或JavaScript语言来构建语言模型应用。这些库包含了丰富的接口，集成了许多开发者能够轻松地使用组件，以及一个将这些组件组合成链（Chains）和代理（Agents）的基本运行时环境。此外，LangChain库还提供了现成的链和代理实现，这些实现都是基于经过验证的架构和最佳实践，使得开发者能够快速启动并构建功能强 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/#content-inner">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/#content-inner">7</a><a class="extend next" rel="next" href="/page/7/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://pics.agiexplained.com/i/2024/03/05/171847_2.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Eryx Lee</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">62</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/eryxlee"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/31/vibe-coding/" title="Vibe Coding">Vibe Coding</a><time datetime="2025-03-31T11:31:47.000Z" title="发表于 2025-03-31 19:31:47">2025-03-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/20/Xinference_vs_vllm_vs_ollama/" title="Xinference、Ollama 和 vLLM 比较">Xinference、Ollama 和 vLLM 比较</a><time datetime="2024-12-20T13:16:51.000Z" title="发表于 2024-12-20 21:16:51">2024-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/13/Xinference_local_install/" title="使用Xinference部署本地大模型">使用Xinference部署本地大模型</a><time datetime="2024-12-13T09:46:18.000Z" title="发表于 2024-12-13 17:46:18">2024-12-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/07/vllm_local_install/" title="使用vLLM部署本地大模型">使用vLLM部署本地大模型</a><time datetime="2024-12-07T12:31:38.000Z" title="发表于 2024-12-07 20:31:38">2024-12-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/01/llama.cpp-build-and-setup/" title="llama.cpp 编译使用">llama.cpp 编译使用</a><time datetime="2024-12-01T11:41:21.000Z" title="发表于 2024-12-01 19:41:21">2024-12-01</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            <a class="card-more-btn" href="/categories/" title="查看更多">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/FastAPI/"><span class="card-category-list-name">FastAPI</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/General/"><span class="card-category-list-name">General</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LLM/"><span class="card-category-list-name">LLM</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LangChain/"><span class="card-category-list-name">LangChain</span><span class="card-category-list-count">17</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Prompt/"><span class="card-category-list-name">Prompt</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Pydantic/"><span class="card-category-list-name">Pydantic</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Python/"><span class="card-category-list-name">Python</span><span class="card-category-list-count">21</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/pytest/"><span class="card-category-list-name">pytest</span><span class="card-category-list-count">5</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/SQLModel/" style="font-size: 1.35em; color: #99a3b1">SQLModel</a> <a href="/tags/Vibe-Coding/" style="font-size: 1.1em; color: #999">Vibe Coding</a> <a href="/tags/ollama/" style="font-size: 1.2em; color: #999da3">ollama</a> <a href="/tags/LLM/" style="font-size: 1.3em; color: #99a1ac">LLM</a> <a href="/tags/Ollama/" style="font-size: 1.1em; color: #999">Ollama</a> <a href="/tags/pytest/" style="font-size: 1.25em; color: #999fa7">pytest</a> <a href="/tags/LangChain/" style="font-size: 1.45em; color: #99a7ba">LangChain</a> <a href="/tags/mkdocs/" style="font-size: 1.1em; color: #999">mkdocs</a> <a href="/tags/Docker/" style="font-size: 1.1em; color: #999">Docker</a> <a href="/tags/vLLM/" style="font-size: 1.15em; color: #999b9e">vLLM</a> <a href="/tags/tools/" style="font-size: 1.1em; color: #999">tools</a> <a href="/tags/FastAPI/" style="font-size: 1.4em; color: #99a5b6">FastAPI</a> <a href="/tags/Cache/" style="font-size: 1.2em; color: #999da3">Cache</a> <a href="/tags/Xinference/" style="font-size: 1.15em; color: #999b9e">Xinference</a> <a href="/tags/ruff/" style="font-size: 1.1em; color: #999">ruff</a> <a href="/tags/Pydantic/" style="font-size: 1.1em; color: #999">Pydantic</a> <a href="/tags/Python/" style="font-size: 1.5em; color: #99a9bf">Python</a> <a href="/tags/Celery/" style="font-size: 1.15em; color: #999b9e">Celery</a> <a href="/tags/llama-cpp/" style="font-size: 1.1em; color: #999">llama.cpp</a> <a href="/tags/RAG/" style="font-size: 1.1em; color: #999">RAG</a> <a href="/tags/Prompt/" style="font-size: 1.1em; color: #999">Prompt</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/03/"><span class="card-archive-list-date">三月 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">十一月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/06/"><span class="card-archive-list-date">六月 2024</span><span class="card-archive-list-count">5</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">62</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-04-02T08:58:27.409Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By Eryx Lee</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a target="_blank" href="https://beian.miit.gov.cn/">浙ICP备2024062350号-1</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>